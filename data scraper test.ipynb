{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from arrow_pd_parser import writer, reader\n",
    "import python_scripts.s3_utils as s3_utils\n",
    "from datetime import datetime, timedelta\n",
    "from mojap_metadata import Metadata\n",
    "\n",
    "\n",
    "\n",
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "def read_json(file_path: str) -> dict:\n",
    "    \"\"\"Reads a json file in as a dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path :\n",
    "        file path of the JSON to read from\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        dictionary representing the json file\n",
    "    \"\"\"\n",
    "    f = open(file_path)\n",
    "    return json.loads(f.read())\n",
    "\n",
    "\n",
    "def get_secrets() -> dict:\n",
    "    return s3_utils.read_json_from_s3(\"alpha-dag-matrix/api_secrets/secrets.json\")\n",
    "\n",
    "\n",
    "def matrix_authenticate(session: requests.Session) -> requests.Session:\n",
    "    # Add this before the error occurs\n",
    "    for handler in logger.handlers:\n",
    "        for record in handler.records:\n",
    "            print(record.__dict__)\n",
    "    secrets = get_secrets()\n",
    "    username = secrets[\"username\"]\n",
    "    password = secrets[\"password\"]\n",
    "\n",
    "    url = \"https://app.matrixbooking.com/api/v1/user/login\"\n",
    "    session.post(url, json={\"username\": username, \"password\": password})\n",
    "    return session\n",
    "\n",
    "\n",
    "def get_booking_categories(session: requests.Session) -> pd.DataFrame:\n",
    "    \"\"\"Returns pandas dataframe containing all booking categories\n",
    "    that are available to organisation\n",
    "\n",
    "     Parameters:\n",
    "    session (requests.sessions.Session): Authenticated session to\n",
    "        matrix booking API\n",
    "    \"\"\"\n",
    "\n",
    "    # Booking categories API url\n",
    "    url_booking_cats = \"https://app.matrixbooking.com/api/v1/category\"\n",
    "\n",
    "    # Make request and create dataframe\n",
    "    res = requests.get(url_booking_cats, cookies=session.cookies).json()\n",
    "    df_booking_categories = pd.json_normalize(res)\n",
    "\n",
    "    return df_booking_categories\n",
    "\n",
    "\n",
    "def make_booking_params(\n",
    "    time_from: str,\n",
    "    time_to: str,\n",
    "    booking_categories: str,\n",
    "    status: str = None,\n",
    "    pageSize: int = None,\n",
    "    pageNum: int = 0,\n",
    ") -> dict:\n",
    "    params = {\n",
    "        \"f\": time_from,\n",
    "        \"t\": time_to,\n",
    "        \"bc\": booking_categories,\n",
    "        \"status\": status,\n",
    "        \"include\": [\"audit\", \"locations\"],\n",
    "        \"pageSize\": pageSize,\n",
    "        \"pageNum\": pageNum,\n",
    "    }\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_payload(session, url, parameters):\n",
    "    resp = session.get(url=url, cookies=session.cookies, params=parameters)\n",
    "    logger.debug(f\"GET {resp.url}\")\n",
    "    logger.debug(f\"response status code: {resp.status_code}\")\n",
    "    return resp\n",
    "\n",
    "\n",
    "def split_s3_path(s3_path: str) -> tuple[str]:\n",
    "    \"\"\"Splits an s3 file path into a bucket and key\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3_path :\n",
    "        The full (incl s3://) path of a file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Tuple of the bucket name and key (file path) within that bucket.\n",
    "    \"\"\"\n",
    "    if s3_path[:2] != \"s3\":\n",
    "        raise ValueError(\"S3 file path should start with 's3://'.\")\n",
    "    path_split = s3_path.split(\"/\")\n",
    "    bucket = path_split[2]\n",
    "    key = \"/\".join(path_split[3:])\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def get_scrape_dates(start_date, end_date):\n",
    "    def daterange(start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days + 1)):\n",
    "            yield datetime.strftime(start_date + timedelta(n), \"%Y-%m-%d\")\n",
    "\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end_date_1 = datetime.now().date() - timedelta(days=1)\n",
    "    end_date_2 = datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "    if end_date_1 < end_date_2:\n",
    "        end_date = end_date_1\n",
    "    else:\n",
    "        end_date = end_date_2\n",
    "\n",
    "    return daterange(start_date, end_date)\n",
    "\n",
    "\n",
    "def scrape_days_from_api(\n",
    "    start_date: str, end_date: str\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Scrapes the matrix API for a given period\n",
    "    Writes outputs to raw-history bucket with folder specified by 'env'\n",
    "\n",
    "    Parameters:\n",
    "        start_date: Start date in format %Y-%m-%d\n",
    "        end_date: End date in format %Y-%m-%d\n",
    "            can also be 'eod' to denote end of day\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "    page_size = 2500\n",
    "    status = [\"CONFIRMED\", \"TENTATIVE\", \"CANCELLED\"]\n",
    "\n",
    "    bookings = []\n",
    "\n",
    "    # Authenticate session with API\n",
    "    ses = requests.session()\n",
    "    matrix_authenticate(ses)\n",
    "\n",
    "    # Get booking categories available\n",
    "    df_booking_categories = get_booking_categories(ses)\n",
    "\n",
    "    # List with unique booking categories\n",
    "    booking_categories = list(df_booking_categories[\"locationKind\"])\n",
    "\n",
    "    # Derive booking parameters\n",
    "    params = make_booking_params(\n",
    "        start_date,\n",
    "        end_date,\n",
    "        booking_categories,\n",
    "        pageNum=0,\n",
    "        pageSize=page_size,\n",
    "        status=status,\n",
    "    )\n",
    "\n",
    "    # Scrape the first page of data\n",
    "    logger.info(\"Scraping page 0\")\n",
    "    data = get_payload(ses, url, params)\n",
    "    rowcount = len(data[\"bookings\"])\n",
    "    logger.info(f\"Records scraped: {rowcount}\")\n",
    "\n",
    "    # Pull out the bookings and location data seperately\n",
    "    bookings = data[\"bookings\"]\n",
    "    locations = data[\"locations\"]\n",
    "\n",
    "    i = 1\n",
    "    total_rows = rowcount\n",
    "    while rowcount == page_size:\n",
    "        logger.info(f\"Scraping page {i}\")\n",
    "        params = make_booking_params(\n",
    "            start_date, end_date, pageNum=i, pageSize=page_size, status=status\n",
    "        )\n",
    "        data = get_payload(ses, url, params)\n",
    "        rowcount = len(data[\"bookings\"])\n",
    "        logger.info(f\"Records scraped: {rowcount}\")\n",
    "        if rowcount > 0:\n",
    "            bookings.extend(data[\"bookings\"])\n",
    "        i += 1\n",
    "        total_rows += rowcount\n",
    "\n",
    "    logger.info(f\"Retrieved {len(locations)} locations\")\n",
    "    logger.info(f\"Retrieved {total_rows} bookings\")\n",
    "\n",
    "    raw_bookings = pd.json_normalize(bookings, sep=\"_\").rename(\n",
    "        mapper=camel_to_snake_case, axis=\"columns\"\n",
    "    )\n",
    "    raw_locations = pd.json_normalize(locations, sep=\"_\").rename(\n",
    "        mapper=camel_to_snake_case, axis=\"columns\"\n",
    "    )\n",
    "\n",
    "    return raw_bookings, raw_locations\n",
    "\n",
    "\n",
    "def camel_to_snake_case(input_str: str) -> str:\n",
    "    # Using regular expressions to find positions with capital letters and insert underscores\n",
    "    s1 = re.sub(\"(.)([A-Z][a-z]+)\", r\"\\1_\\2\", input_str)\n",
    "    s2 = re.sub(\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", s1)\n",
    "\n",
    "    # Handle the case where multiple uppercase letters are present\n",
    "    snake_case_str = re.sub(\"([a-z])([A-Z]+)\", r\"\\1_\\2\", s2).lower()\n",
    "\n",
    "    return snake_case_str\n",
    "\n",
    "\n",
    "def rename_df(df: pd.DataFrame, renames: dict) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        _description_\n",
    "    renames : _type_\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    # Find any names that are not in the renames dict\n",
    "    renames_data = [name for name in renames if name not in df.columns]\n",
    "    if len(renames_data) > 0:\n",
    "        logger.info(f\"{renames_data} not in scraped dataframe\")\n",
    "    else:\n",
    "        df = df.rename(columns=renames)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fix_faulty_time_col(df, col):\n",
    "    column = df[col].copy()\n",
    "    # Check for missing parts (seconds, minutes, hours, microseconds)\n",
    "    missing_parts = column.apply(\n",
    "        lambda x: (pd.notna(x) and (len(str(x).split(\":\")) < 3 or \".\" not in str(x)))\n",
    "    )\n",
    "\n",
    "    def format_timestamp(raw_string):\n",
    "        # Generate dynamic format based on missing parts\n",
    "        num_parts = len(raw_string.split(\":\"))\n",
    "\n",
    "        format_str = (\n",
    "            \"%Y-%m-%dT\"\n",
    "            + \":\".join([\"%H\", \"%M\", \"%S\"][:num_parts])\n",
    "            + (\".%f\" if \".\" in raw_string else \"\")\n",
    "        )\n",
    "\n",
    "        return pd.to_datetime(raw_string, format=format_str).strftime(\n",
    "            \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "        )\n",
    "\n",
    "    column.loc[missing_parts] = column.loc[missing_parts].apply(format_timestamp)\n",
    "    return column\n",
    "\n",
    "\n",
    "def fix_faulty_time_cols(df):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    bookings_metadata = Metadata.from_json(\"metadata/db_v2/preprod/bookings.json\")\n",
    "    for col in bookings_metadata:\n",
    "        if \"timestamp\" in col[\"type\"]:\n",
    "            if col[\"name\"] in df.columns:\n",
    "                df[col[\"name\"]] = fix_faulty_time_col(df, col[\"name\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_raw_data_to_s3(\n",
    "    bookings: pd.DataFrame, locations: pd.DataFrame, start_date: str, env: str\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bookings : _type_\n",
    "        _description_\n",
    "    locations : _type_\n",
    "        _description_\n",
    "    start_date : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    raw_bookings_loc = f\"{land_location}/bookings/{start_date}/raw-{start_date}.jsonl\"\n",
    "    raw_locations_loc = f\"{land_location}/locations/{start_date}/raw-{start_date}.jsonl\"\n",
    "    bookings = rename_df(bookings, bookings_renames)\n",
    "    bookings = fix_faulty_time_cols(bookings)\n",
    "    locations = rename_df(locations, location_renames)\n",
    "    writer.write(\n",
    "        bookings,\n",
    "        raw_bookings_loc,\n",
    "    )\n",
    "    writer.write(\n",
    "        locations,\n",
    "        raw_locations_loc,\n",
    "    )\n",
    "    logger.info(f\"{env}: raw booking and location data written to {land_location}.\")\n",
    "\n",
    "\n",
    "def scrape_and_write_raw_data(start_date, env):\n",
    "    bookings, locations = scrape_days_from_api(start_date, \"eod\")\n",
    "    write_raw_data_to_s3(bookings, locations, start_date, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = requests.session()\n",
    "matrix_authenticate(ses)\n",
    "df = get_booking_categories(ses)\n",
    "booking_categories = list(df[\"locationKind\"])\n",
    "status = [\"CONFIRMED\", \"TENTATIVE\", \"CANCELLED\"]\n",
    "params = {\n",
    "    \"f\": \"2023-12-12\",\n",
    "    \"t\": \"eod\",\n",
    "    \"bc\": booking_categories,\n",
    "    \"status\": status,\n",
    "    \"include\": \"audit\",\n",
    "    \"pageSize\": 2500,\n",
    "    \"pageNum\": 0,\n",
    "}\n",
    "url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "\n",
    "# Scrape the first page of data\n",
    "data = get_payload(ses, url, params)\n",
    "test_df = pd.json_normalize(data.json())\n",
    "writer.write(\n",
    "    test_df,\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_with_status.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = requests.session()\n",
    "matrix_authenticate(ses)\n",
    "df = get_booking_categories(ses)\n",
    "booking_categories = list(df[\"locationKind\"])\n",
    "status = [\"CONFIRMED\", \"TENTATIVE\", \"CANCELLED\"]\n",
    "params = {\n",
    "    \"f\": \"2023-12-12\",\n",
    "    \"t\": \"eod\",\n",
    "    \"bc\": booking_categories,\n",
    "    # \"status\": status,\n",
    "    \"include\": \"audit\",\n",
    "    \"pageSize\": 2500,\n",
    "    \"pageNum\": 0,\n",
    "}\n",
    "url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "\n",
    "# Scrape the first page of data\n",
    "data = get_payload(ses, url, params)\n",
    "test_df = pd.json_normalize(data.json())\n",
    "writer.write(\n",
    "    test_df,\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_without_status.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_status_df = reader.read(\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_without_status.parquet\"\n",
    ")\n",
    "with_status_df = reader.read(\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_with_status.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            No of Unique Locations: 1614\n",
      "            No of Unique organisations: 37\n",
      "            No of Unique bookings ids: 2401\n",
      "            Different Statuses: <StringArray>\n",
      "['CONFIRMED', 'TENTATIVE']\n",
      "Length: 2, dtype: string\n",
      "            Different Locations: <StringArray>\n",
      "['DESK', 'ROOM', 'CAR_SPACE', 'OFFICE']\n",
      "Length: 4, dtype: string\n",
      "            \n",
      "          \n",
      "\n",
      "            No of Unique Locations: 654\n",
      "            No of Unique organisations: 1\n",
      "            No of Unique bookings ids: 1222\n",
      "            Different Statuses: <StringArray>\n",
      "['CONFIRMED', 'CANCELLED', 'TENTATIVE']\n",
      "Length: 3, dtype: string\n",
      "            Different Locations: <StringArray>\n",
      "['DESK', 'CAR_SPACE', 'ROOM', 'OFFICE']\n",
      "Length: 4, dtype: string\n",
      "            \n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_info(df):\n",
    "    unique_locations = len(df.locationId.unique())\n",
    "    unique_organisations = len(df[\"organisation.id\"].unique())\n",
    "    unique_booking_ids = len(df.id.unique())\n",
    "    status_returns = df.status.unique()\n",
    "    location_kind_returns = df.locationKind.unique()\n",
    "    print(\n",
    "        f\"\"\"\n",
    "            No of Unique Locations: {unique_locations}\n",
    "            No of Unique organisations: {unique_organisations}\n",
    "            No of Unique bookings ids: {unique_booking_ids}\n",
    "            Different Statuses: {status_returns}\n",
    "            Different Locations: {location_kind_returns}\n",
    "            \n",
    "          \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "get_info(without_status_df), get_info(with_status_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_status_df.loc[with_status_df['status'] == ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            DESK\n",
       "1            DESK\n",
       "2            DESK\n",
       "3            DESK\n",
       "4            DESK\n",
       "          ...    \n",
       "2396    CAR_SPACE\n",
       "2397         ROOM\n",
       "2398         ROOM\n",
       "2399         ROOM\n",
       "2400         ROOM\n",
       "Name: locationKind, Length: 2401, dtype: string"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_status_df.locationKind.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
