{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Queries\n",
    "\n",
    "This notebook was created to help document issues found with the Matrix API.\n",
    "\n",
    "We have observed unusual behaviour with the API depending on whether we provide a **status** parameter in the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define standard functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from arrow_pd_parser import writer, reader\n",
    "import python_scripts.s3_utils as s3_utils\n",
    "from datetime import datetime, timedelta\n",
    "from mojap_metadata import Metadata\n",
    "\n",
    "\n",
    "\n",
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "def read_json(file_path: str) -> dict:\n",
    "    \"\"\"Reads a json file in as a dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path :\n",
    "        file path of the JSON to read from\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        dictionary representing the json file\n",
    "    \"\"\"\n",
    "    f = open(file_path)\n",
    "    return json.loads(f.read())\n",
    "\n",
    "\n",
    "def get_secrets() -> dict:\n",
    "    return s3_utils.read_json_from_s3(\"alpha-dag-matrix/api_secrets/secrets.json\")\n",
    "\n",
    "\n",
    "def matrix_authenticate(session: requests.Session) -> requests.Session:\n",
    "    # Add this before the error occurs\n",
    "    for handler in logger.handlers:\n",
    "        for record in handler.records:\n",
    "            print(record.__dict__)\n",
    "    secrets = get_secrets()\n",
    "    username = secrets[\"username\"]\n",
    "    password = secrets[\"password\"]\n",
    "\n",
    "    url = \"https://app.matrixbooking.com/api/v1/user/login\"\n",
    "    session.post(url, json={\"username\": username, \"password\": password})\n",
    "    return session\n",
    "\n",
    "\n",
    "def get_booking_categories(session: requests.Session) -> pd.DataFrame:\n",
    "    \"\"\"Returns pandas dataframe containing all booking categories\n",
    "    that are available to organisation\n",
    "\n",
    "     Parameters:\n",
    "    session (requests.sessions.Session): Authenticated session to\n",
    "        matrix booking API\n",
    "    \"\"\"\n",
    "\n",
    "    # Booking categories API url\n",
    "    url_booking_cats = \"https://app.matrixbooking.com/api/v1/category\"\n",
    "\n",
    "    # Make request and create dataframe\n",
    "    res = requests.get(url_booking_cats, cookies=session.cookies).json()\n",
    "    df_booking_categories = pd.json_normalize(res)\n",
    "\n",
    "    return df_booking_categories\n",
    "\n",
    "\n",
    "def make_booking_params(\n",
    "    time_from: str,\n",
    "    time_to: str,\n",
    "    booking_categories: str,\n",
    "    status: str = None,\n",
    "    pageSize: int = None,\n",
    "    pageNum: int = 0,\n",
    ") -> dict:\n",
    "    params = {\n",
    "        \"f\": time_from,\n",
    "        \"t\": time_to,\n",
    "        \"bc\": booking_categories,\n",
    "        \"status\": status,\n",
    "        \"include\": [\"audit\", \"locations\"],\n",
    "        \"pageSize\": pageSize,\n",
    "        \"pageNum\": pageNum,\n",
    "    }\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_payload(session, url, parameters):\n",
    "    resp = session.get(url=url, cookies=session.cookies, params=parameters)\n",
    "    logger.debug(f\"GET {resp.url}\")\n",
    "    logger.debug(f\"response status code: {resp.status_code}\")\n",
    "    return resp\n",
    "\n",
    "\n",
    "def split_s3_path(s3_path: str) -> tuple[str]:\n",
    "    \"\"\"Splits an s3 file path into a bucket and key\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3_path :\n",
    "        The full (incl s3://) path of a file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Tuple of the bucket name and key (file path) within that bucket.\n",
    "    \"\"\"\n",
    "    if s3_path[:2] != \"s3\":\n",
    "        raise ValueError(\"S3 file path should start with 's3://'.\")\n",
    "    path_split = s3_path.split(\"/\")\n",
    "    bucket = path_split[2]\n",
    "    key = \"/\".join(path_split[3:])\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def get_scrape_dates(start_date, end_date):\n",
    "    def daterange(start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days + 1)):\n",
    "            yield datetime.strftime(start_date + timedelta(n), \"%Y-%m-%d\")\n",
    "\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end_date_1 = datetime.now().date() - timedelta(days=1)\n",
    "    end_date_2 = datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "    if end_date_1 < end_date_2:\n",
    "        end_date = end_date_1\n",
    "    else:\n",
    "        end_date = end_date_2\n",
    "\n",
    "    return daterange(start_date, end_date)\n",
    "\n",
    "\n",
    "def scrape_days_from_api(\n",
    "    start_date: str, end_date: str\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Scrapes the matrix API for a given period\n",
    "    Writes outputs to raw-history bucket with folder specified by 'env'\n",
    "\n",
    "    Parameters:\n",
    "        start_date: Start date in format %Y-%m-%d\n",
    "        end_date: End date in format %Y-%m-%d\n",
    "            can also be 'eod' to denote end of day\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "    page_size = 2500\n",
    "    status = [\"CONFIRMED\", \"TENTATIVE\", \"CANCELLED\"]\n",
    "\n",
    "    bookings = []\n",
    "\n",
    "    # Authenticate session with API\n",
    "    ses = requests.session()\n",
    "    matrix_authenticate(ses)\n",
    "\n",
    "    # Get booking categories available\n",
    "    df_booking_categories = get_booking_categories(ses)\n",
    "\n",
    "    # List with unique booking categories\n",
    "    booking_categories = list(df_booking_categories[\"locationKind\"])\n",
    "\n",
    "    # Derive booking parameters\n",
    "    params = make_booking_params(\n",
    "        start_date,\n",
    "        end_date,\n",
    "        booking_categories,\n",
    "        pageNum=0,\n",
    "        pageSize=page_size,\n",
    "        status=status,\n",
    "    )\n",
    "\n",
    "    # Scrape the first page of data\n",
    "    logger.info(\"Scraping page 0\")\n",
    "    data = get_payload(ses, url, params)\n",
    "    rowcount = len(data[\"bookings\"])\n",
    "    logger.info(f\"Records scraped: {rowcount}\")\n",
    "\n",
    "    # Pull out the bookings and location data seperately\n",
    "    bookings = data[\"bookings\"]\n",
    "    locations = data[\"locations\"]\n",
    "\n",
    "    i = 1\n",
    "    total_rows = rowcount\n",
    "    while rowcount == page_size:\n",
    "        logger.info(f\"Scraping page {i}\")\n",
    "        params = make_booking_params(\n",
    "            start_date, end_date, pageNum=i, pageSize=page_size, status=status\n",
    "        )\n",
    "        data = get_payload(ses, url, params)\n",
    "        rowcount = len(data[\"bookings\"])\n",
    "        logger.info(f\"Records scraped: {rowcount}\")\n",
    "        if rowcount > 0:\n",
    "            bookings.extend(data[\"bookings\"])\n",
    "        i += 1\n",
    "        total_rows += rowcount\n",
    "\n",
    "    logger.info(f\"Retrieved {len(locations)} locations\")\n",
    "    logger.info(f\"Retrieved {total_rows} bookings\")\n",
    "\n",
    "    raw_bookings = pd.json_normalize(bookings, sep=\"_\").rename(\n",
    "        mapper=camel_to_snake_case, axis=\"columns\"\n",
    "    )\n",
    "    raw_locations = pd.json_normalize(locations, sep=\"_\").rename(\n",
    "        mapper=camel_to_snake_case, axis=\"columns\"\n",
    "    )\n",
    "\n",
    "    return raw_bookings, raw_locations\n",
    "\n",
    "\n",
    "def camel_to_snake_case(input_str: str) -> str:\n",
    "    # Using regular expressions to find positions with capital letters and insert underscores\n",
    "    s1 = re.sub(\"(.)([A-Z][a-z]+)\", r\"\\1_\\2\", input_str)\n",
    "    s2 = re.sub(\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", s1)\n",
    "\n",
    "    # Handle the case where multiple uppercase letters are present\n",
    "    snake_case_str = re.sub(\"([a-z])([A-Z]+)\", r\"\\1_\\2\", s2).lower()\n",
    "\n",
    "    return snake_case_str\n",
    "\n",
    "\n",
    "def rename_df(df: pd.DataFrame, renames: dict) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        _description_\n",
    "    renames : _type_\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    # Find any names that are not in the renames dict\n",
    "    renames_data = [name for name in renames if name not in df.columns]\n",
    "    if len(renames_data) > 0:\n",
    "        logger.info(f\"{renames_data} not in scraped dataframe\")\n",
    "    else:\n",
    "        df = df.rename(columns=renames)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fix_faulty_time_col(df, col):\n",
    "    column = df[col].copy()\n",
    "    # Check for missing parts (seconds, minutes, hours, microseconds)\n",
    "    missing_parts = column.apply(\n",
    "        lambda x: (pd.notna(x) and (len(str(x).split(\":\")) < 3 or \".\" not in str(x)))\n",
    "    )\n",
    "\n",
    "    def format_timestamp(raw_string):\n",
    "        # Generate dynamic format based on missing parts\n",
    "        num_parts = len(raw_string.split(\":\"))\n",
    "\n",
    "        format_str = (\n",
    "            \"%Y-%m-%dT\"\n",
    "            + \":\".join([\"%H\", \"%M\", \"%S\"][:num_parts])\n",
    "            + (\".%f\" if \".\" in raw_string else \"\")\n",
    "        )\n",
    "\n",
    "        return pd.to_datetime(raw_string, format=format_str).strftime(\n",
    "            \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "        )\n",
    "\n",
    "    column.loc[missing_parts] = column.loc[missing_parts].apply(format_timestamp)\n",
    "    return column\n",
    "\n",
    "\n",
    "def fix_faulty_time_cols(df):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    bookings_metadata = Metadata.from_json(\"metadata/db_v2/preprod/bookings.json\")\n",
    "    for col in bookings_metadata:\n",
    "        if \"timestamp\" in col[\"type\"]:\n",
    "            if col[\"name\"] in df.columns:\n",
    "                df[col[\"name\"]] = fix_faulty_time_col(df, col[\"name\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_raw_data_to_s3(\n",
    "    bookings: pd.DataFrame, locations: pd.DataFrame, start_date: str, env: str\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bookings : _type_\n",
    "        _description_\n",
    "    locations : _type_\n",
    "        _description_\n",
    "    start_date : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    raw_bookings_loc = f\"{land_location}/bookings/{start_date}/raw-{start_date}.jsonl\"\n",
    "    raw_locations_loc = f\"{land_location}/locations/{start_date}/raw-{start_date}.jsonl\"\n",
    "    bookings = rename_df(bookings, bookings_renames)\n",
    "    bookings = fix_faulty_time_cols(bookings)\n",
    "    locations = rename_df(locations, location_renames)\n",
    "    writer.write(\n",
    "        bookings,\n",
    "        raw_bookings_loc,\n",
    "    )\n",
    "    writer.write(\n",
    "        locations,\n",
    "        raw_locations_loc,\n",
    "    )\n",
    "    logger.info(f\"{env}: raw booking and location data written to {land_location}.\")\n",
    "\n",
    "\n",
    "def scrape_and_write_raw_data(start_date, env):\n",
    "    bookings, locations = scrape_days_from_api(start_date, \"eod\")\n",
    "    write_raw_data_to_s3(bookings, locations, start_date, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make API requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide booking categories (all) and status (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = requests.session()\n",
    "matrix_authenticate(ses)\n",
    "df = get_booking_categories(ses)\n",
    "booking_categories = list(df[\"locationKind\"])\n",
    "status = [\"CONFIRMED\", \"TENTATIVE\", \"CANCELLED\"]\n",
    "params = {\n",
    "    \"f\": \"2023-12-12\",\n",
    "    \"t\": \"eod\",\n",
    "    \"bc\": booking_categories,\n",
    "    \"status\": status,\n",
    "    \"include\": \"audit\",\n",
    "    \"pageSize\": 2500,\n",
    "    \"pageNum\": 0,\n",
    "}\n",
    "url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "\n",
    "# Scrape the first page of data\n",
    "data = get_payload(ses, url, params)\n",
    "test_df = pd.json_normalize(data.json())\n",
    "print(data.url)\n",
    "writer.write(\n",
    "    test_df,\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_with_status.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide booking categories (all) but no status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = requests.session()\n",
    "matrix_authenticate(ses)\n",
    "df = get_booking_categories(ses)\n",
    "booking_categories = list(df[\"locationKind\"])\n",
    "status = [\"CONFIRMED\", \"TENTATIVE\", \"CANCELLED\"]\n",
    "params = {\n",
    "    \"f\": \"2023-12-12\",\n",
    "    \"t\": \"eod\",\n",
    "    \"bc\": booking_categories,\n",
    "    # \"status\": status,\n",
    "    \"include\": \"audit\",\n",
    "    \"pageSize\": 2500,\n",
    "    \"pageNum\": 0,\n",
    "}\n",
    "url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "\n",
    "# Scrape the first page of data\n",
    "data = get_payload(ses, url, params)\n",
    "print(data.url)\n",
    "test_df = pd.json_normalize(data.json())\n",
    "writer.write(\n",
    "    test_df,\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_without_status.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide booking categories (all) but a single status \n",
    "\n",
    "### Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = requests.session()\n",
    "matrix_authenticate(ses)\n",
    "df = get_booking_categories(ses)\n",
    "booking_categories = list(df[\"locationKind\"])\n",
    "status = [\"CONFIRMED\"]\n",
    "params = {\n",
    "    \"f\": \"2023-12-12\",\n",
    "    \"t\": \"eod\",\n",
    "    \"bc\": booking_categories,\n",
    "    \"status\": status,\n",
    "    \"include\": \"audit\",\n",
    "    \"pageSize\": 2500,\n",
    "    \"pageNum\": 0,\n",
    "}\n",
    "url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "\n",
    "# Scrape the first page of data\n",
    "data = get_payload(ses, url, params)\n",
    "print(data.url)\n",
    "test_df = pd.json_normalize(data.json())\n",
    "writer.write(\n",
    "    test_df,\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_with_status_confirmed.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = requests.session()\n",
    "matrix_authenticate(ses)\n",
    "df = get_booking_categories(ses)\n",
    "booking_categories = list(df[\"locationKind\"])\n",
    "status = [\"TENTATIVE\"]\n",
    "params = {\n",
    "    \"f\": \"2023-12-12\",\n",
    "    \"t\": \"eod\",\n",
    "    \"bc\": booking_categories,\n",
    "    \"status\": status,\n",
    "    \"include\": \"audit\",\n",
    "    \"pageSize\": 2500,\n",
    "    \"pageNum\": 0,\n",
    "}\n",
    "url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "\n",
    "# Scrape the first page of data\n",
    "data = get_payload(ses, url, params)\n",
    "print(data.url)\n",
    "test_df = pd.json_normalize(data.json())\n",
    "writer.write(\n",
    "    test_df,\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_with_status_tentative.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = requests.session()\n",
    "matrix_authenticate(ses)\n",
    "df = get_booking_categories(ses)\n",
    "booking_categories = list(df[\"locationKind\"])\n",
    "status = [\"CANCELLED\"]\n",
    "params = {\n",
    "    \"f\": \"2023-12-12\",\n",
    "    \"t\": \"eod\",\n",
    "    \"bc\": booking_categories,\n",
    "    \"status\": status,\n",
    "    \"include\": \"audit\",\n",
    "    \"pageSize\": 2500,\n",
    "    \"pageNum\": 0,\n",
    "}\n",
    "url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "\n",
    "# Scrape the first page of data\n",
    "data = get_payload(ses, url, params)\n",
    "print(data.url)\n",
    "test_df = pd.json_normalize(data.json())\n",
    "writer.write(\n",
    "    test_df,\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_with_status_cancelled.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide no booking categories and no status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = requests.session()\n",
    "matrix_authenticate(ses)\n",
    "df = get_booking_categories(ses)\n",
    "booking_categories = list(df[\"locationKind\"])\n",
    "status = [\"CONFIRMED\", \"TENTATIVE\", \"CANCELLED\"]\n",
    "params = {\n",
    "    \"f\": \"2023-12-12\",\n",
    "    \"t\": \"eod\",\n",
    "    # \"bc\": booking_categories,\n",
    "    # \"status\": status,\n",
    "    \"include\": \"audit\",\n",
    "    \"pageSize\": 2500,\n",
    "    \"pageNum\": 0,\n",
    "}\n",
    "url = \"https://app.matrixbooking.com/api/v1/booking\"\n",
    "\n",
    "# Scrape the first page of data\n",
    "data = get_payload(ses, url, params)\n",
    "test_df = pd.json_normalize(data.json())\n",
    "print(data.url)\n",
    "writer.write(\n",
    "    test_df,\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_with_no_bc_no_status.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read back data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataframes\n",
    "without_status_df = reader.read(\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_without_status.parquet\"\n",
    ")\n",
    "with_status_df = reader.read(\n",
    "    \"s3://alpha-dag-matrix/testing-api/called_with_status.parquet\"\n",
    ")\n",
    "with_status_confirmed_df = reader.read(\"s3://alpha-dag-matrix/testing-api/called_with_status_confirmed.parquet\"\n",
    ")\n",
    "with_status_tent_df = reader.read(\"s3://alpha-dag-matrix/testing-api/called_with_status_tentative.parquet\"\n",
    ")\n",
    "with_status_cancelled_df = reader.read(\"s3://alpha-dag-matrix/testing-api/called_with_status_cancelled.parquet\"\n",
    ")\n",
    "without_bc_or_status_df = reader.read(\"s3://alpha-dag-matrix/testing-api/called_with_no_bc_no_status.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(df):\n",
    "    unique_locations = len(df.locationId.unique())\n",
    "    unique_organisations = len(df[\"organisation.id\"].unique())\n",
    "    unique_booking_ids = len(df.id.unique())\n",
    "    status_returns = df.status.unique()\n",
    "    location_kind_returns = df.locationKind.unique()\n",
    "    sources = df.source.unique()\n",
    "    print(\n",
    "        f\"\"\"\n",
    "            No of Unique Locations: {unique_locations}\n",
    "            No of Unique organisations: {unique_organisations}\n",
    "            No of Unique bookings ids: {unique_booking_ids}\n",
    "            Different Statuses: {status_returns}\n",
    "            Different Locations: {location_kind_returns}           \n",
    "          \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All booking types provided explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No status provided \n",
    "get_info(without_status_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All status provided\n",
    "get_info(with_status_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status confirmed only\n",
    "get_info(with_status_confirmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status tentative only\n",
    "get_info(with_status_tent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status cancelled \n",
    "get_info(with_status_cancelled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info(without_bc_or_status_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volumes of status compared to booking type\n",
    "pd.crosstab(without_status_df['locationKind'], without_status_df['status'], dropna=False, margins=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the data\n",
    "\n",
    "### No status vs all status provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data and retain an indicator \n",
    "df_full = pd.merge(without_status_df,\n",
    "                   with_status_df,\n",
    "                   how='outer',\n",
    "                   left_on='id',\n",
    "                   right_on='id',\n",
    "                   indicator=True\n",
    "                    )\n",
    "# Volumes\n",
    "df_full['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With status provided\n",
    "\n",
    "We expect those in 'right only' to be cancelled only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those in 'with status only' we expect all to be cancelled\n",
    "df_right = df_full[df_full[\"_merge\"]=='right_only'].copy()\n",
    "df_right['status_y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With status not provided (Only)\n",
    "\n",
    "What can we say about those that weren't common to both?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those 'left only' what organisations are they?\n",
    "df_left = df_full[df_full[\"_merge\"]=='left_only'].copy()\n",
    "df_left['organisation.name_x'].value_counts()\n",
    "\n",
    "# This includes some 43 - need to work out why these 43s are not in the other...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left_43 = df_left[df_left['organisation.id_x'] == 43]\n",
    "df_left_43.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left_43.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status - confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_status_confirmed_df['organisation.id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all 'confirmed' common to the 'without status' query?\n",
    "df_confirmed_common = pd.merge(with_status_confirmed_df,\n",
    "                                without_status_df,\n",
    "                                how='outer',\n",
    "                                left_on = 'id',\n",
    "                                right_on = 'id',\n",
    "                                indicator=True)\n",
    "df_confirmed_common['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status - Tentative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_status_tent_df['organisation.id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all 'confirmed' common to the 'without status' query?\n",
    "df_tent_common = pd.merge(with_status_tent_df,\n",
    "                                without_status_df,\n",
    "                                how='outer',\n",
    "                                left_on = 'id',\n",
    "                                right_on = 'id',\n",
    "                                indicator=True)\n",
    "df_tent_common['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status - Cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_status_cancelled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether we get any more 'cancelled' bookings if we provide \n",
    "# the status explicitly\n",
    "df_cancelled_common = pd.merge(with_status_cancelled_df,\n",
    "                               with_status_df,\n",
    "                               how='inner',\n",
    "                               left_on='id',\n",
    "                               right_on='id',\n",
    "                               indicator=True\n",
    "\n",
    ")\n",
    "df_cancelled_common[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results where we don't provide booking categories or status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect everything to match\n",
    "df_nobc_no_status_common = pd.merge(without_bc_or_status_df,\n",
    "                                    without_status_df,\n",
    "                                    how='outer',\n",
    "                                    left_on='id',\n",
    "                                    right_on='id',\n",
    "                                    indicator=True)\n",
    "df_nobc_no_status_common['_merge'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
